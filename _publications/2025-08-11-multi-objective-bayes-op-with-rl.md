---
title: "Multi-Objective Bayesian Optimization with Reinforcement Learning for Edge Deployment of DNNs on Microcontrollers"
collection: publications
category: conferences
permalink: /publication/multi-objective-bayes-op-with-rl
excerpt: "Deploying deep neural networks (DNNs) on microcontroller units (MCUs) is a common trend to process the increasing amount of sensor data generated at the edge, but it is challenging due to resource and latency constraints. Neural architecture search (NAS) helps automate the search for suitable DNNs. In our original work \"Combining Multi-Objective Bayesian Optimization with Reinforcement Learning for TinyML\", we present a novel NAS strategy for edge deployment using multi-objective Bayesian optimization (MOBOpt) and reinforcement learning (RL). Our approach efficiently balances accuracy, memory, and computational complexity, outperforming existing methods on multiple datasets and architectures such as ResNet-18 and MobileNetV3."
date: 2025-08-11
venue: 'The Genetic and Evolutionary Computation Conference (GECCO)'
paperurl: 'https://doi.org/10.1145/3712255.3734232'
#openurl: 'https://doi.org/10.1145/3712255.3734232'
slidesurl: '../files/presentation_gecco25_deutel_slides_only.pdf'
highlight: '../files/multi_obj_gecco_highlight.png'
citation: 'Deutel, M., Kontes, G., Mutschler, C., & Teich, J. (2025). Multi-Objective Bayesian Optimization with Reinforcement Learning for Edge Deployment of DNNs on Microcontrollers. The Genetic and Evolutionary Computation Conference (GECCO).'
---

Deploying deep neural networks (DNNs) on microcontroller units (MCUs) is a common trend to process the increasing amount of sensor data generated at the edge, but it is challenging due to resource and latency constraints. Neural architecture search (NAS) helps automate the search for suitable DNNs. In our original work \"Combining Multi-Objective Bayesian Optimization with Reinforcement Learning for TinyML\", we present a novel NAS strategy for edge deployment using multi-objective Bayesian optimization (MOBOpt) and reinforcement learning (RL). Our approach efficiently balances accuracy, memory, and computational complexity, outperforming existing methods on multiple datasets and architectures such as ResNet-18 and MobileNetV3.